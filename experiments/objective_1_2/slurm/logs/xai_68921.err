2025-03-13 16:23:33.722473: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-13 16:23:33.902635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-13 16:23:33.941418: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-03-13 16:23:33.947301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-13 16:23:34.013574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-13 16:23:36.490587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Processing XAI methods:   0%|          | 0/3 [00:00<?, ?it/s]Processing XAI methods:  33%|███▎      | 1/3 [00:08<00:17,  8.79s/it]Processing XAI methods:  67%|██████▋   | 2/3 [00:17<00:08,  8.95s/it]Processing XAI methods:  67%|██████▋   | 2/3 [00:22<00:11, 11.16s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/mqa887/audio-xai/src/xai/objective1_experiments.py", line 224, in <module>
    main() 
    ^^^^^^
  File "/home/mqa887/audio-xai/src/xai/objective1_experiments.py", line 213, in main
    results = experiment.run_experiments()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mqa887/audio-xai/src/xai/objective1_experiments.py", line 153, in run_experiments
    method_results = self.evaluate_explanations(method, explanations, x_batch, y_batch)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mqa887/audio-xai/src/xai/objective1_experiments.py", line 105, in evaluate_explanations
    scores = metric_func(
             ^^^^^^^^^^^^
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/metrics/randomisation/random_logit.py", line 225, in __call__
    return super().__call__(
           ^^^^^^^^^^^^^^^^^
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/metrics/base.py", line 290, in __call__
    result = self.evaluate_batch(**data_batch)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/metrics/randomisation/random_logit.py", line 332, in evaluate_batch
    self.evaluate_instance(model, x, y, a)
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/metrics/randomisation/random_logit.py", line 278, in evaluate_instance
    a_perturbed = self.explain_batch(model, np.expand_dims(x, axis=0), y_off)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/metrics/base.py", line 930, in explain_batch
    asserts.assert_attributions(x_batch=x_batch, a_batch=a_batch)
  File "/home/mqa887/.conda/envs/myvm/lib/python3.12/site-packages/quantus/helpers/asserts.py", line 180, in assert_attributions
    assert not np.all((a_batch == 0)), (
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: The elements in the attribution vector are all equal to zero, which may cause inconsistent results since many metrics rely on ordering. Recompute the explanations.
